# -*- coding: utf-8 -*-
"""ACRIMA_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gKXtGHQ04tZLXqNjCROF9ggWUbB4GRgq
"""

import os
import re
import cv2
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix
from tensorflow.keras.applications import VGG16, ResNet50, DenseNet121
from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from google.colab import drive
from vit_keras import vit

# Mount Google Drive
drive.mount('/content/drive')
image_folder_path = '/content/drive/MyDrive/21BDS0137/ACRIMA/Images'

# Define the path to the ACRIMA folder
acrima_folder = '/content/drive/MyDrive/21BDS0137/ACRIMA/Images'

# Initialize lists to hold images and labels
acrima_images = []
acrima_labels = []

# Define patterns to identify normal and glaucomatous images
normal_pattern = re.compile(r'Im\d+_ACRIMA')
glaucomatous_pattern = re.compile(r'Im\d+_g_ACRIMA')

# Load images and labels
for image_name in os.listdir(acrima_folder):
    image_path = os.path.join(acrima_folder, image_name)
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB
    image = cv2.resize(image, (224, 224))  # Resize to match the input size of the model

    if normal_pattern.match(image_name):
        acrima_images.append(image)
        acrima_labels.append(0)  # 0 for normal
    elif glaucomatous_pattern.match(image_name):
        acrima_images.append(image)
        acrima_labels.append(1)  # 1 for glaucomatous

# Convert lists to numpy arrays
acrima_images = np.array(acrima_images)
acrima_labels = np.array(acrima_labels)

# Normalize the images
acrima_images = acrima_images / 255.0

# Split data into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(acrima_images, acrima_labels, test_size=0.2, random_state=42)

# Apply data augmentation to reduce overfitting
datagen = ImageDataGenerator(
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

datagen.fit(x_train)

# Function to build model architecture
from keras.layers import Reshape # Import the Reshape class

def build_model(base_model, num_classes=1):
    for layer in base_model.layers:
        layer.trainable = False

    x = base_model.output

    # Check if the output shape is 2D and reshape if necessary
    if len(x.shape) == 2:
        x = Reshape((1, 1, x.shape[-1]))(x) # Reshape to 4D for GlobalAveragePooling2D

    x = GlobalAveragePooling2D()(x)
    x = Dense(512, activation='relu')(x)
    x = Dropout(0.5)(x)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.5)(x)
    predictions = Dense(num_classes, activation='sigmoid')(x)

    model = Model(inputs=base_model.input, outputs=predictions)
    return model

# Load base models and Visual Transformer (ViT)
vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
resnet50_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
densenet121_base = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
vit_base = vit.vit_b16(image_size=224, activation='sigmoid', pretrained=True, include_top=False, pretrained_top=False)

# Build models
vgg16_model = build_model(vgg16_base)
resnet50_model = build_model(resnet50_base)
densenet121_model = build_model(densenet121_base)
vit_model = build_model(vit_base)

# Compile models
models = [vgg16_model, resnet50_model, densenet121_model, vit_model]
for model in models:
    model.compile(optimizer=Adam(learning_rate=1e-4),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

# Callbacks for early stopping and reducing learning rate
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)

# Train models with data augmentation to prevent overfitting
histories = []
for model in models:
    print(f"Training model: {model.name}")
    history = model.fit(datagen.flow(x_train, y_train, batch_size=32),
                        validation_data=(x_val, y_val),
                        epochs=50,
                        callbacks=[early_stopping, reduce_lr])
    histories.append(history)

# Evaluate and print accuracy for each model
for model, name in zip(models, ['VGG16', 'ResNet50', 'DenseNet121', 'ViT']):
    loss, accuracy = model.evaluate(x_val, y_val)
    print(f'{name} Model - Loss: {loss}, Accuracy: {accuracy}')

# Logistic Regression
logistic_model = LogisticRegression(max_iter=1000)
x_train_flat = x_train.reshape(x_train.shape[0], -1)  # Flatten image data for Logistic Regression
x_val_flat = x_val.reshape(x_val.shape[0], -1)
logistic_model.fit(x_train_flat, y_train)
logistic_predictions = logistic_model.predict(x_val_flat)
logistic_accuracy = accuracy_score(y_val, logistic_predictions)
print(f'Logistic Regression Accuracy: {logistic_accuracy}')

# Simple Neural Network
nn_model = Sequential([
    Flatten(input_shape=(224, 224, 3)),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])
nn_model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])
nn_history = nn_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=30,
                          callbacks=[early_stopping, reduce_lr])
nn_loss, nn_accuracy = nn_model.evaluate(x_val, y_val)
print(f'Simple Neural Network - Loss: {nn_loss}, Accuracy: {nn_accuracy}')

# Plot Training Histories
def plot_history(history, title):
    plt.plot(history.history['accuracy'], label='train_accuracy')
    plt.plot(history.history['val_accuracy'], label='val_accuracy')
    plt.plot(history.history['loss'], label='train_loss')
    plt.plot(history.history['val_loss'], label='val_loss')
    plt.title(title)
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy/Loss')
    plt.legend()
    plt.show()

for history, name in zip(histories, ['VGG16', 'ResNet50', 'DenseNet121', 'ViT']):
    plot_history(history, f'{name} Training History')

plot_history(nn_history, 'Simple Neural Network Training History')

from tensorflow.keras.applications import VGG16

vgg16_model = VGG16(weights='imagenet', include_top=True) # Ensure you load the model with appropriate weights

def compute_gradcam(model, image, class_index):
    grad_model = Model([model.inputs], [model.get_layer('block5_conv3').output, model.output])
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(np.expand_dims(image, axis=0))
        loss = predictions[:, class_index]

    grads = tape.gradient(loss, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]
    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1)
    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)
    return heatmap

# Function to apply Grad-CAM and create superimposed image
def apply_gradcam(model, image, true_label):
    heatmap = compute_gradcam(model, image, true_label)
    heatmap = cv2.resize(heatmap, (224, 224))
    heatmap = np.uint8(255 * heatmap)
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)

    image = np.uint8(image * 255)
    superimposed_image = cv2.addWeighted(image, 0.6, heatmap, 0.4, 0)
    return superimposed_image

# Apply Grad-CAM to 100 validation images
num_images = 100
grid_size = int(np.ceil(np.sqrt(num_images)))

fig, axes = plt.subplots(grid_size, grid_size, figsize=(20, 20))
fig.suptitle("Grad-CAM Visualization on 100 Images", fontsize=24)

for i in range(num_images):
    row = i // grid_size
    col = i % grid_size

    image = x_val[i]
    label = y_val[i]

    superimposed_image = apply_gradcam(vgg16_model, image, label)

    axes[row, col].imshow(superimposed_image)
    axes[row, col].axis('off')
    axes[row, col].set_title(f'True: {"Glaucoma" if label == 1 else "Normal"}', fontsize=8)

# Remove any unused subplots
for i in range(num_images, grid_size * grid_size):
    row = i // grid_size
    col = i % grid_size
    fig.delaxes(axes[row, col])

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Assuming you have trained your models and their histories are stored in these variables
vgg16_history = histories[0]
resnet50_history = histories[1]
densenet121_history = histories[2]
vit_history = histories[3]

def plot_history(history, model_name):
    plt.figure(figsize=(12, 5))

    # Plot accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title(f'{model_name} Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    # Plot loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title(f'{model_name} Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

# Plot histories for each model
plot_history(vgg16_history, 'VGG16')
plot_history(resnet50_history, 'ResNet50')
plot_history(densenet121_history, 'DenseNet121')
plot_history(vit_history, 'Vision Transformer (ViT)')

# Optionally, you can also plot the Simple Neural Network history
plot_history(nn_history, 'Simple Neural Network')

# Compare all models' validation accuracy
plt.figure(figsize=(10, 6))
plt.plot(vgg16_history.history['val_accuracy'], label='VGG16')
plt.plot(resnet50_history.history['val_accuracy'], label='ResNet50')
plt.plot(densenet121_history.history['val_accuracy'], label='DenseNet121')
plt.plot(vit_history.history['val_accuracy'], label='ViT')
plt.plot(nn_history.history['val_accuracy'], label='Simple NN')
plt.title('Model Comparison - Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Validation Accuracy')
plt.legend()
plt.show()

# Compare all models' validation loss
plt.figure(figsize=(10, 6))
plt.plot(vgg16_history.history['val_loss'], label='VGG16')
plt.plot(resnet50_history.history['val_loss'], label='ResNet50')
plt.plot(densenet121_history.history['val_loss'], label='DenseNet121')
plt.plot(vit_history.history['val_loss'], label='ViT')
plt.plot(nn_history.history['val_loss'], label='Simple NN')
plt.title('Model Comparison - Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Validation Loss')
plt.legend()
plt.show()